{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jYDi4Rf6gGTT"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "jsonl_file_path = \"/content/train_manifest.jsonl\" # path to your jsonl file\n",
        "\n",
        "train_examples = []\n",
        "\n",
        "with open(jsonl_file_path, \"r\") as file:\n",
        "    for line in file:\n",
        "        train_examples.append(json.loads(line))\n"
      ],
      "metadata": {
        "id": "nDilsOWIgaD2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df_dict = {\"audio_path\": [], \"duration\": [], \"text\": []}"
      ],
      "metadata": {
        "id": "cDd_gdoogeSS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for train_example in train_examples:\n",
        "  train_df_dict['audio_path'].append(train_example['audio_filepath'])\n",
        "  train_df_dict['duration'].append(train_example['duration'])\n",
        "  train_df_dict['text'].append(train_example['text'])\n",
        "\n",
        "train_df = pd.DataFrame(train_df_dict)"
      ],
      "metadata": {
        "id": "ZPRMhXPVgsY4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "i8SukEN1hSk6",
        "outputId": "8e484f33-8a8d-43e9-d68d-59ae9a2c51db"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                audio_path   duration  \\\n",
              "0  task2/super_cleaned_audios/lesson99.wav   338.0304   \n",
              "1  task2/super_cleaned_audios/lesson66.wav   675.9441   \n",
              "2  task2/super_cleaned_audios/lesson72.wav  1548.9848   \n",
              "3  task2/super_cleaned_audios/lesson73.wav   902.1759   \n",
              "4  task2/super_cleaned_audios/lesson67.wav   431.6677   \n",
              "\n",
              "                                                text  \n",
              "0  the next thing that we will see is how do you ...  \n",
              "1  i will do will do early stopping where again w...  \n",
              "2  so in this module we will talk about better in...  \n",
              "3  now we will end with something known as batch ...  \n",
              "4  so next we look at on ensemble methods and thi...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ec11ab5-0ade-4ef8-8acc-9533371323a8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>audio_path</th>\n",
              "      <th>duration</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>task2/super_cleaned_audios/lesson99.wav</td>\n",
              "      <td>338.0304</td>\n",
              "      <td>the next thing that we will see is how do you ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>task2/super_cleaned_audios/lesson66.wav</td>\n",
              "      <td>675.9441</td>\n",
              "      <td>i will do will do early stopping where again w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>task2/super_cleaned_audios/lesson72.wav</td>\n",
              "      <td>1548.9848</td>\n",
              "      <td>so in this module we will talk about better in...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>task2/super_cleaned_audios/lesson73.wav</td>\n",
              "      <td>902.1759</td>\n",
              "      <td>now we will end with something known as batch ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>task2/super_cleaned_audios/lesson67.wav</td>\n",
              "      <td>431.6677</td>\n",
              "      <td>so next we look at on ensemble methods and thi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ec11ab5-0ade-4ef8-8acc-9533371323a8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3ec11ab5-0ade-4ef8-8acc-9533371323a8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3ec11ab5-0ade-4ef8-8acc-9533371323a8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1506e1d5-cf88-4fa1-a6b0-20fa8a4758b9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1506e1d5-cf88-4fa1-a6b0-20fa8a4758b9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1506e1d5-cf88-4fa1-a6b0-20fa8a4758b9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 114,\n  \"fields\": [\n    {\n      \"column\": \"audio_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 114,\n        \"samples\": [\n          \"task2/super_cleaned_audios/lesson90.wav\",\n          \"task2/super_cleaned_audios/lesson67.wav\",\n          \"task2/super_cleaned_audios/lesson115.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 752.345937568829,\n        \"min\": 49.4346,\n        \"max\": 5114.0852,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          1206.7784,\n          431.6677,\n          115.7438\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 114,\n        \"samples\": [\n          \"so now we will go to the next module we will talk about some success stories on  imagenet right so this is the challenge which actually made convolutional neural  networks very famous back in two thousand and twelve   so they are going to look at some algorithms in fact two more hopefully today    so this is the story right so there is this challenge or competition called imagenet  large scale visual recognition competition right that is what ilsvrc stands for and  this was a data set created which had one thousand categories it actually has one thousandzero categories  but in the competition we use only thousand of those categories yes   so one thousand plus one thousand i think the roughly the data set size is one million and so that is what  was used for training a classifier and i am talking about twozeroonezero the pre deep era right i  mean so of course deep era networks existed at that time but the participants and these  challenges and that time were relying on the classical machine learning approaches so  what was that approach take the image   student refer time zerooneonesix feature     extract features which features  student refer time zeroonetwozero  predominantly  student sift and hawk  sift and hawk features were the predominant features at that time and then you train a  classifier on top of that and then you use things like on symbols or better handcrafted  features and things like that certain more tricks on top of that so that with that on this  data in twozeroonezero the error was twoeighttwo percent that means if i give you a test set of one thousand  images you will make twoeighttwo errors on that right that is what this means then in oneone there  was still some progress this was again pre deep era and there was this error came down  to twofiveeight and then in two thousand and twelve there was this alexnet which was a deep convolutional  neural network applied to the task of image classification and it gave a dramatic  reduction right from twofiveeight to onesixfour   and was i think absolute in absolute terms eight to nine eight to nine percentage better than the best  system in that competition that year ok so that was in two thousand and twelve in twozeroonethree there was further  improvement on a different architecture for doing this and that give a further error  reduction of oneoneseven then in twozeroonefour there was vgg net so these are all three that we are going  to see today which give a further error reduction of seventhree then google decided to join  the party and they make it sixty-seven and as i have said before then afterwards microsoft got  crazy and they brought it out in threefiveseven and this is when we started making claims that a  convolutional neural network has become better at this task than humans right   because if you show these one thousand images to a human even a human is bound to make a  threefive percent more than threefive percent error that means because some of these images would  be blurred so i would not be very sure whether this is a bulldog or a different type of  dog or something like that right so i even a human cannot really recognize it correctly  and that is the whole hype around how convolutional neural networks have beating  human level performance on this particular task right   and let us see so this was all the shallow pre deep era the first architecture was eight  layers and i think this was called a varied no this probably not this yeah the second  architecture was also eight layers then we had onenine then twotwo and then onefivetwo right thats how the  progress has happened so these are all the architectures that we are going to look at  today or at least some of them today and the rest maybe tomorrow   ok so we will start with alexnet and i am going to tell you the exact architecture of  alexnet what was refused what did it actually use     so the input was an rgb image so it had a depth of three and it was twotwoseven \\uf0b4 twotwoseven that is  what the data set input was all the images in the data set were to twotwoseven \\uf0b4 twotwoseven cross three so  the first thing that they did was they decided to use ninesix filters can you read that  anyways i will say it outright   so they resided to use ninesix filters with a spatial extent of oneone cross oneone a size of four and  padding of zero ok so the moment you see size a stride of four what do you know is going  to happen there is going to be some shrinkage roughly by how much onefourth  right so now can you compute these three things what was wtwo what was htwo and what  was the number of parameters in this layer we will do it for a few of these layers and  then i will just rush through that so whats wtwo going to be you have already done this  computation right the exercise that we did was exactly this computation so there was  fifty-five cross fifty-five and what is the depth going to be i want everyone to say that  student refer time zerofiveonefive  ok and what is the number of parameters  student refer time zerofivetwozero  ninesix into  student oneone  oneone into  student oneone  oneone into three don\\u2019t forget the depth the depth is three here     so that is the number of parameters that they had in this layer ok oneone into oneone into three into  ninesix now what is the next layer going to be a max pooling layer     ok so they had a max pooling layer where they used a three cross three max pooling that  means you are going to pick up max from a three cross three grid and the stride was two that  means we are going to get half the output and now can you tell me what wtwo htwo would  be roughly half of fifty-five fifty-five right so twoseven twoseven     and what is the number of parameter is going to be don\\u2019t be lazy everyone be say it   student zero  zero right so that is the max pooling layer   now what is the size of your input volume at this point  student twoseven  twoseven cross twoseven cross  student ninesix  ninesix as opposed to the original input which was twotwoseven cross twotwoseven cross three so as you keep  progressing your width and height is decreasing but your depth is increasing because  you are using more and more filters to capture more and more patterns in the images     now so you have twoseven \\uf0b4 twoseven \\uf0b4 ninesix then they decided to use twofivesix filters each of size five \\uf0b4 five  with a stride of one and padding of zero ok is it right so how many parameters do you have  now  student refer time zerosixfivethree  twofivesix into   student five into five  five into five into  student ninesix  ninesix    so thats the number of parameters that you will have and the size since would decrease  only by one right because you have a stride of it will decrease by two because a filter size is  five and you have a stride of five ok    so these are the number of parameters we had zerosix million parameters in this layer  what is the next layer going to be pooling     so you do a max pooling again you do a three \\uf0b4 three you do a stride of two so your width in  height is going to decrease the depth does not change remember in max pooling the  depth does not change because the max pooling operation is per feature map it is not  across the depth fine then use a three \\uf0b4 three filter and threeeightfour of those     so how many parameters would you have  student refer time zerosevenfourthree  threeeightfour into three cross three into twofivesix the depth   so now you guys get it so i will not bore you anymore      and then you have a convolution operation again which is a threeeightfour convolutions each of  size three \\uf0b4 three and so many parameters followed by a convolution operation again followed  by a max pooling operation then followed by a fully connected layer    so what would i do to this twofivesix \\uf0b4 two \\uf0b4 two i will fatten it so i will get what dimensional  output  student onezerotwofour  onezerotwofour twofivesix into two into two so this onezerotwofour dimensional vector i am going to fully connect it to  a fourzeroninesix dimensional vector how many parameters four million right four into onezero raise to six  right so roughly four million      then you have another four million another fourzeroninesix vector fully connected how many  parameters   student onesix million  onesix million then you have the one thousand classes that you are interested in right so again  fully connected so you get the full architecture anyone has any questions no one  wants to know why this particular configuration among all the possible configurations  why not onezero layers why not first eight cross eight filters why not nine cross nine filters  unfortunately no one knows laughing  student refer time zeroeightfivenine  so this i mean see this what this is what would happen right now we get into something  known as hyper parameter tuning right so what are the hyper parameters in this  network the kernel size is and the number of filters right so you would have tried a  lot of these things evaluated on the validation set seen which one gives the best  accuracy and then chosen right so that is probably what would have happened but  there is not enough insight into how this particular architecture came up   apart from some things right that three curves three neighborhood sounds reasonable initially  when you have the full image you use larger filter sizes because you want to capture a  lot of things there but once the image has shrunken you use smaller filter sizes so those  are some rational decisions which look reasonable but why these three convolutional filter  layers back to back instead of convolution max pooling convolution max pooling and so  on right  so the some of those things are not clear so just in case you are wondering do not  wonder this is just the architecture this is known as modestly named as alexnet so  that is laughing yeah and so i said that this has eight layers but you clearly see more than  eight layers here so why did i say that has eight layers which are the layers we are not  counting  student refer time onezeroonezero  why   student refer time onezeroonetwo  because they have no parameter right so when you count the number of layers you only  count those layers which have parameters so you have five convolutions and three fully  connected layers     then so the total number of parameters in this network is twosevenfifty-five million parameters and  ok at this point i will and obviously you notice that most of these parameters were there  in the fully connected layer so you had four million here then onesix million here and then  again four million here right   so roughly twofour million of the twoseven million parameters were there in the fully connected  layer you see that skew in the number of parameters ok    and i will just look at the fully connected layer again so the last max pooling layer  actually gave you a twofivesix cross two cross two output you just flatten it to get a onezerotwofour  dimensional vector and then you connected fully to the fourzeroninesix vector right so that is what  i mean by a fully connected layer why do you move max fully   so the reason for that is basically to shrink the size of the image right because after that  if if you keep working with this size right then the number of parameters is going to  really blow up a by using a larger stripe yeah both of them are feasible right so now  see from here remember that we had the original image sizes twotwoseven cross twotwoseven and by the  end we were just left with two cross two  and then adding a fully connected layer on that makes sense right if i had not done this  shrinkage throughout either by increasing the stride of the convolution layer or by doing  max pooling right then you would have left with something of the order of twozerozero cross  twozerozero here and then you have to do a fully connected on top of that is just infeasible right  it just throws away all the hard work that you have done by doing weight sharing and  sparse connectivity right so that is not feasible   there are also papers with say which i think it is titled fully convolutional neural  network which does not have any max pooling layers and they show that that also works  fine in fact when we see vgg net we will see that it has back to back convolution  layers and very few max fully layer right so these are all things which people have  trained   not so many years two years the challenge came out in twozeroonezero and in two thousand and twelve this was used  right so it is like not really a large gap right and if you read the original paper they  had to do a lot of tricks to actually make this work it was not as simple as i am showing  it of course now with all the stability which comes from these platforms tensor flow  pytorch you can probably just go and implement this as it is and you should be able to  reproduce the results but six years back that was not the case there was a lot of hard  work involved in getting this too work and they this was also the paper which  introduced the relu nonlinearity in the context of convolutional neural networks right  so they had to change from sigmoid or tan edge to relu   a lot of these small small things which they had done and at that time it is also not  possible with the existing hardware to train this on the given gpus that you had at that  time so they had to do some splitting across gpus and so on so it was not as simple  as it is today with all the hardware as well as api developments or platform  developments around this right so probably that is why it took two years to yeah sure   so each of these things so after you do the convolution operation you pass it through  the relu nonlinearity ok so what does that mean is that the convolution operation  gave you a feature map every entry here was just a weighted average of the neighbors  right you take this entry or rather you take this feature map and create a new feature map  where every entry here is the sigmoid of every entry here do you get that or not sorry  sigmoid some nonlinearity and they use the relu has the nonlinearity so you do get  everyone gets this so all the convolution layers are followed by a relu nonlinearity  layer  so you get this volume pass it through the relu and get a new volume but i have just  shown that as a single operation it is before pulling so this was the fully connected layer  so now we look at the next architecture which is zfnet    now i am going to compare zfnet with alexnet so on the top you will see alexnet  on the bottom you will see zfnet ok so again the input was the same twotwoseven \\uf0b4 twotwoseven \\uf0b4 three  now instead of oneone cross oneone filters zfnet decided to use seven \\uf0b4 seven filters and their rationale  was that you do not need such large neighborhoods you do not need as small as three \\uf0b4 three  but probably you need at least as much as seven \\uf0b4 seven you do not need oneone \\uf0b4 oneone so that is the  first change that they did and that would also result in some parameter pruning right  because the number of parameters now would be seven cross seven into three so the difference in  the number of parameters at this layer for zfnet which is at the bottom and alexnet  which is at the top would be this how many of you get this ok so thats in the  difference in the number of parameters so now the output volume still remains the  same its fifty-five \\uf0b4 fifty-five \\uf0b4 ninesix     then again they had the same max pooling operation this layer there was no difference  between zfnet and alexnet and then after that you had again layer three which was  exactly the same as alexnet     then layer four again the same as zfnet afterwards layer five instead of threeeightfour filters they  decided to use fiveonetwo filters the rest of the thing remains the same that means the size or  the spatial extent of the filter remains the same that again results in some difference in  the parameters so thats the number of parameters that got added in zfnet as opposed to  alex net   and of course the  oh sorry sorry oh sorry the bottom one is a zfnet yeah that is  correct sorry so in zfnet you had fiveonetwo filters as opposed to threeeightfour filters in alex net ok  is it fine     and then the next layer again instead of threeeightfour filters they had onezerotwofour filters     then again instead of twofivesix they had fiveonetwo filters and then a max pooling layer then the  same dense fully connected layers ok    so everyone gets this this is the difference between the two architectures and this led  to that difference in the error of around three to four percent is that we have seen earlier    so difference the total number of parameters was onefourfive million and of course zfnet had  more parameters because is that it has these more filters in the deeper layers ok so we  go to the last point which is may be more in that vgg net     so again in the case of vgg net the input was ok so i just want to i will not see it  refer time onesixfourone in so the input was again the same it was rgb cross twotwoseven cross  twotwoseven   so this is what the vgg architecture looks like they have so in vgg network  throughout ok wait so how many layers this zfnet have eight so you only count the  pink boxes because the those has ones which have two parameters now vgg net has  slightly more number of layers but in all the convolution layers they use three cross three filters  right from the beginning they use three cross three filters ok so you have the first  convolution layer then another convolution layer another convolution another max  pooling layer followed by two convolution layers then a max pooling layer followed by three  convolution layers max pooling just keep adding box is writing just because you can  and then you have the fully connected layers   so again there is not much intuition for why onesix in fact later on someone came if this is  the vgg onesix architecture because it says onesix layers later on some of someone came up  with the vgg onenine architecture which has onenine layers right so a lot of this is data center  even right so you try your best to get the best possible accuracy on the imagenet data  and that is the architecture you came up with right   but as long as how many of few feel comfortable with what is happening right and i  mean when i say comfortable i mean that you really understand the gory details of  what is happening at each layer in terms of input volumes output volumes number of  parameters how are you going to train this network end to end can you see how are you  going to train this so you will get some loss here that is going to propagate all the way  back to the first layer right and this propagation is going to happen over some sparse  connections that fine now this is one very important point that i have skipped and  which none of you is questioning is everything that is happening here differentiable  student refer time oneeightthreeeight  what happens to max pooling is max pooling or differentiable operation so i am  going to ask you this how are you just note this down how are you going to back  propagate to the max pooling layer because you need to see whether the max pooling  layer is actually a differentiable layer or not  so here i just some statistics about vgg  net everyone is writing that down laughing this perhaps means i will not ask it   the kernel size is three cross three throughout the total number of parameters in non fully  connected layers is onesix million the total number of parameters in fully connected layers  is onetwotwo million so you see that this fully connected layer is really a problem it like really  hogs all the lime that it has the maximum number of parameters there right and so and  the most number of parameters are there in the first fully connected layer because you  have this fiveonetwo \\uf0b4 seven \\uf0b4 seven you remember then alex net and zfnet the last layer was twofivesix \\uf0b4  two \\uf0b4 two which has definitely more manageable than this layer which has grown almost eight  times in size but not even eight actually four into four into two right onesix threetwo times in size right  so that is really blown up the number of parameters in the first fully connected layer  so you just imagine the i mean you have such a deep layer and then you realize that all  the main number of parameters are there in this one particular layer everything else is  much fewer parameters or orders of parameters less number of parameter is less then  this one fully connected layer   \",\n          \"so next we look at on ensemble methods and this is just to build the intuitions for  something known as dropout which is very popular technique in deep neural networks  and convolution neural networks and even recurrent neural networks    so how many you have seen ensembles before seen it in machine learning ensemble  was not done in machinery done with ok ravi did it so as a combine so the ensemble is  essentially just the combining the output of different models to reduce the generalization  error right why does that make sense have these different models all of these would  have different biases and variances right  so now you are combining them so i will end up with a better thing on the test error  right so that is the idea behind ensemble now the models could correspond to different  classifiers right for example here i have a logistic regression and svm and a naive  bayes i have trained them independently using the same data or different subsets of the  data and a test time i am taking a prediction from all of them and then taking an  ensemble of those predictions that is the basic idea  now it could be different instances of the same classifier trained with different hyper  parameters i could have the same neural network a threelayer neural network but trained  with different hyper parameters so the hyper parameters could be learning rate it could  be batch size it could be the number of neurons in each layer and so on right so it  could be same classifier but different hyper parameters different features right so  instead of looking at all the one hundred features that i have given i could train these classifiers  with different subsets of the features ok or different samples of the training data    so bagging is one such ensemble method where you have different instances of the same  classifier which are trained on different samples of the training data ok so i have one  classifiers trained on a subset t one of the training data another classifier trained on a  subset t two of the training data and so on right  and so each of these model is trained with  a different sample of the data    now when would bagging actually work what would you want these classifiers to be  so each classifier is going to make certain errors  what do you want these errors across classifiers to be dependent independent   student independent  independent right so if one classifier makes the errors on certain test instances other  classifier makes errors on a different set of test instances and the third classifier makes  errors on a very different set of instances that is the condition that you are looking for  right there is errors if all of them make error on the same instance then all of them are  collectively going to make an error on the final prediction also right  because it is like i asked three guys all of them gave me the wrong answer so my final  answer is going to be wrong but at least two of these three guys gave me the correct answer  then my final answer is going to be correct right so that means the errors that these  models make i want these errors to be independent if i treat error as a random variable i  want these errors to be independent  so so consider a set of k such logistic regression models suppose that each model  makes an error epsilon i on the test example now let epsilon i be drawn from a zero mean  multivariate normal distribution so the variance is equal to v and how many such  epsilons do i have how many such distributions i am considering  student k  k right because for each classifier there is a distribution so then i can compute the  covariance between these random variables ok i will add that let that covariance be c is  that fineok now the true the error made by the average prediction of all the models is  going to be given by this model one made an error of epsilon one model two made an error of  epsilon two  so the average error is going to be given by this now what is this expected squared  error this is the error this is the expectation this is the square that is the expected  squared error is that fine again this is a square of a sum so it will lead to a lot of terms  of the form epsilon i squares and what will happen now which terms will go to zero    the terms having epsilon i epsilon j again the same thing they are independent so i can  write the expectation of a product as the product of expectations and those expectations  are zero so this is what it is going to look like what is this oh sorry actually we had not  assumed that the covalence  what is this right and what is this covariance i am sorry i have not we had assumed  that there is some covariance said wed not assume they are independent right we would  want it to be independent but in the general case we will assume some covariance and  then i will show you the special case where they are independent  so then how many vs do i have here k right and how many cs do i have here    this summation is k into k minus one right or i equal to one to k and j equal to i plus one to k  fine and so this is what it looks like now can you make some inferences from this  equation this is what the expected mean square error is going to be now think in terms  of variance covariance and tell me when would this be beneficial i have already told  you the answer if the errors are independent what would covariance be zero right  so then what is the mean square error one by k one by k into v right so that means bagging  would work when your classifiers the k classifiers that you are combining    if the errors are independent then the mean square error should actually have been v  right for a single classifier it was v right because mean square error is nothing but the  expectation of the error expectation of epsilon i square which is nothing but v  but if you are if you are combining k classifiers and if these classifiers are independent  in terms of their errors then your mean square error is going to be one by k into v because  this term is going to disappear ok now if your classifiers are perfectly correlated then  what would happen and basically c is equal to v right is that fine so now what would  happen what is the net result if i substitute this as v going to be v right  so if you are all your classifiers are perfectly correlated that is the other case we had  tried taken and all of them are making errors on the same test instances and the same  errors right then you will not get any benefit of doing bagging but if you look at the  other extreme where all your errors are independent or all your classifiers are making  independent errors then you will get a benefit your expected mean square error would go  down from v to one by k into v everyone gets that    so this was just to develop an intuition that taking an ensemble helps right and using  this intuition now we are going to see at how to do this ensemble in the case of deep  neural networks  \",\n          \"so let us start s last lecture we are looking at encoder decoder models and we saw that  a bunch of problems from different domains and different modalities images text videos  and so on and even this cross modal or multi modal applications where you are taking  a video and trying to describe it so video is one modality description texts is another  modality and so on  we were able to propose modals for all of these using this encoder \\u2013 decoder  architecture and then we motivated this attention mechanism where we said that  encoder decoder is trying to do this silly thing where it tries to encode the entire input  once and that is what how humans do it he do this back and forth thing where at every  time step if we are trying to produce a translation or a single word in the translation we  just focus on certain words in the input sentence and kind of ignore the other  so the attention mechanism which is this bunch of equations that you see here that  allowed you a neural way of modelling attention and the key thing to note here is a there  was a supervision for the attention no one actually tells us that this is the portion of the  text which is important at time step t but they still works better because this is the better  modelling choice and i give you that bicycle analogy and also it is a better modelling  choice we are able to no one has given you these supervisions but you are still have  more parameters in the model to learn this kind of a behaviour    and then we also saw that we could actually visualise these attention based and from  some experiments on some papers we saw that actually learn some meaningful  attentions in the particular case on the figure on the on the right hand side so the one  that clearly shows that for a monotonic kind of a translation scenario between english  and french most of the attentions weights are along a diagram and that is exactly what  you would expect right  so that is where we end it  \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv(\"train_data.csv\", index = False)"
      ],
      "metadata": {
        "id": "xPrsVNoKZXuy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_hours, total_utterances = 0, 0\n",
        "total_utterances = len(train_df['duration'])\n",
        "total_hours = sum(train_df['duration']) / 3600\n",
        "print(f\"total duration (in hours): {total_hours} \\n total_utterances: {total_utterances}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "djbiEO-klLXj",
        "outputId": "b0f5f9a1-f1b5-49a7-8ad8-05c3558974f6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total duration (in hours): 27.276061416666664 \n",
            " total_utterances: 114\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "texts = train_df[\"text\"].values.tolist()\n",
        "set_of_words, set_of_chars = set(), set()\n",
        "\n",
        "all_words = \" \".join(texts).split()\n",
        "all_chars = list(\" \".join(texts))\n",
        "\n",
        "for word in all_words:\n",
        "  set_of_words.add(word)\n",
        "\n",
        "for chars in all_chars:\n",
        "  set_of_chars.add(chars)\n",
        "\n",
        "print(f\"total unique words: {len(set_of_words)} \\n total unique characters: {len(set_of_chars)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kfcepE9zjGhL",
        "outputId": "2b17f6da-8929-47d8-bf3b-4a45707c5099"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total unique words: 6023 \n",
            " total unique characters: 50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "global_variables_dict = {\"total_utterances\": total_utterances,\n",
        "                         \"total_hours\": total_hours,\n",
        "                         \"vocabulary_size\": len(set_of_words),\n",
        "                         \"character_size\": len(set_of_chars),\n",
        "                         \"characters\": set_of_chars}\n",
        "\n",
        "print(global_variables_dict)\n",
        "print(global_variables_dict['characters'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJ_NfsAzhX7c",
        "outputId": "4c4b7092-deb8-489a-bf4c-f03fa7ae624b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'total_utterances': 114, 'total_hours': 27.276061416666664, 'vocabulary_size': 6023, 'character_size': 50, 'characters': {'2', '\\uf073', 'p', 'c', 'f', '\\uf061', '3', '\\uf02b', 'z', ',', 'w', 'y', 'b', '\\uf0b4', 'n', '’', '\\uf071', '0', 't', 'h', 's', '1', 'x', 'q', 'j', '7', '\\uf0b6', 'o', 'd', 'm', '5', 'l', '“', 'u', '9', '4', '6', '-', 'a', 'v', '–', 'k', '‘', 'r', '8', 'g', 'i', 'ˆ', 'e', ' '}}\n",
            "{'2', '\\uf073', 'p', 'c', 'f', '\\uf061', '3', '\\uf02b', 'z', ',', 'w', 'y', 'b', '\\uf0b4', 'n', '’', '\\uf071', '0', 't', 'h', 's', '1', 'x', 'q', 'j', '7', '\\uf0b6', 'o', 'd', 'm', '5', 'l', '“', 'u', '9', '4', '6', '-', 'a', 'v', '–', 'k', '‘', 'r', '8', 'g', 'i', 'ˆ', 'e', ' '}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#extension of dataframe for histograms\n",
        "\n",
        "def word_count(text):\n",
        "  word_set = set()\n",
        "  for word in text.split():\n",
        "    word_set.add(word)\n",
        "\n",
        "  return len(word_set)\n",
        "\n",
        "def char_count(text):\n",
        "  char_set = set()\n",
        "  for char in list(text):\n",
        "    char_set.add(char)\n",
        "\n",
        "  return len(char_set)\n",
        "\n",
        "train_df['#words'] = train_df['text'].apply(word_count)\n",
        "train_df['#characters'] = train_df['text'].apply(char_count)\n",
        "train_df['duration'] = train_df['duration'].apply(lambda x: x/60)"
      ],
      "metadata": {
        "id": "AQjuu5m1nFHA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qO3iXeoNnNq8",
        "outputId": "5d6986a0-39d5-4013-b1b4-8977844604be"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                audio_path   duration  \\\n",
              "0  task2/super_cleaned_audios/lesson99.wav   5.633840   \n",
              "1  task2/super_cleaned_audios/lesson66.wav  11.265735   \n",
              "2  task2/super_cleaned_audios/lesson72.wav  25.816413   \n",
              "3  task2/super_cleaned_audios/lesson73.wav  15.036265   \n",
              "4  task2/super_cleaned_audios/lesson67.wav   7.194462   \n",
              "\n",
              "                                                text  #words  #characters  \n",
              "0  the next thing that we will see is how do you ...     276           30  \n",
              "1  i will do will do early stopping where again w...     428           27  \n",
              "2  so in this module we will talk about better in...     615           31  \n",
              "3  now we will end with something known as batch ...     504           32  \n",
              "4  so next we look at on ensemble methods and thi...     290           27  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d0cdf90e-5b02-4f14-a905-f5234690f117\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>audio_path</th>\n",
              "      <th>duration</th>\n",
              "      <th>text</th>\n",
              "      <th>#words</th>\n",
              "      <th>#characters</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>task2/super_cleaned_audios/lesson99.wav</td>\n",
              "      <td>5.633840</td>\n",
              "      <td>the next thing that we will see is how do you ...</td>\n",
              "      <td>276</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>task2/super_cleaned_audios/lesson66.wav</td>\n",
              "      <td>11.265735</td>\n",
              "      <td>i will do will do early stopping where again w...</td>\n",
              "      <td>428</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>task2/super_cleaned_audios/lesson72.wav</td>\n",
              "      <td>25.816413</td>\n",
              "      <td>so in this module we will talk about better in...</td>\n",
              "      <td>615</td>\n",
              "      <td>31</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>task2/super_cleaned_audios/lesson73.wav</td>\n",
              "      <td>15.036265</td>\n",
              "      <td>now we will end with something known as batch ...</td>\n",
              "      <td>504</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>task2/super_cleaned_audios/lesson67.wav</td>\n",
              "      <td>7.194462</td>\n",
              "      <td>so next we look at on ensemble methods and thi...</td>\n",
              "      <td>290</td>\n",
              "      <td>27</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d0cdf90e-5b02-4f14-a905-f5234690f117')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d0cdf90e-5b02-4f14-a905-f5234690f117 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d0cdf90e-5b02-4f14-a905-f5234690f117');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-38faa8ab-78f8-4db1-8fcd-36af25743369\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-38faa8ab-78f8-4db1-8fcd-36af25743369')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-38faa8ab-78f8-4db1-8fcd-36af25743369 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train_df",
              "summary": "{\n  \"name\": \"train_df\",\n  \"rows\": 114,\n  \"fields\": [\n    {\n      \"column\": \"audio_path\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 114,\n        \"samples\": [\n          \"task2/super_cleaned_audios/lesson90.wav\",\n          \"task2/super_cleaned_audios/lesson67.wav\",\n          \"task2/super_cleaned_audios/lesson115.wav\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12.539098959480484,\n        \"min\": 0.82391,\n        \"max\": 85.23475333333334,\n        \"num_unique_values\": 114,\n        \"samples\": [\n          20.112973333333333,\n          7.194461666666667,\n          1.9290633333333331\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 114,\n        \"samples\": [\n          \"so now we will go to the next module we will talk about some success stories on  imagenet right so this is the challenge which actually made convolutional neural  networks very famous back in two thousand and twelve   so they are going to look at some algorithms in fact two more hopefully today    so this is the story right so there is this challenge or competition called imagenet  large scale visual recognition competition right that is what ilsvrc stands for and  this was a data set created which had one thousand categories it actually has one thousandzero categories  but in the competition we use only thousand of those categories yes   so one thousand plus one thousand i think the roughly the data set size is one million and so that is what  was used for training a classifier and i am talking about twozeroonezero the pre deep era right i  mean so of course deep era networks existed at that time but the participants and these  challenges and that time were relying on the classical machine learning approaches so  what was that approach take the image   student refer time zerooneonesix feature     extract features which features  student refer time zeroonetwozero  predominantly  student sift and hawk  sift and hawk features were the predominant features at that time and then you train a  classifier on top of that and then you use things like on symbols or better handcrafted  features and things like that certain more tricks on top of that so that with that on this  data in twozeroonezero the error was twoeighttwo percent that means if i give you a test set of one thousand  images you will make twoeighttwo errors on that right that is what this means then in oneone there  was still some progress this was again pre deep era and there was this error came down  to twofiveeight and then in two thousand and twelve there was this alexnet which was a deep convolutional  neural network applied to the task of image classification and it gave a dramatic  reduction right from twofiveeight to onesixfour   and was i think absolute in absolute terms eight to nine eight to nine percentage better than the best  system in that competition that year ok so that was in two thousand and twelve in twozeroonethree there was further  improvement on a different architecture for doing this and that give a further error  reduction of oneoneseven then in twozeroonefour there was vgg net so these are all three that we are going  to see today which give a further error reduction of seventhree then google decided to join  the party and they make it sixty-seven and as i have said before then afterwards microsoft got  crazy and they brought it out in threefiveseven and this is when we started making claims that a  convolutional neural network has become better at this task than humans right   because if you show these one thousand images to a human even a human is bound to make a  threefive percent more than threefive percent error that means because some of these images would  be blurred so i would not be very sure whether this is a bulldog or a different type of  dog or something like that right so i even a human cannot really recognize it correctly  and that is the whole hype around how convolutional neural networks have beating  human level performance on this particular task right   and let us see so this was all the shallow pre deep era the first architecture was eight  layers and i think this was called a varied no this probably not this yeah the second  architecture was also eight layers then we had onenine then twotwo and then onefivetwo right thats how the  progress has happened so these are all the architectures that we are going to look at  today or at least some of them today and the rest maybe tomorrow   ok so we will start with alexnet and i am going to tell you the exact architecture of  alexnet what was refused what did it actually use     so the input was an rgb image so it had a depth of three and it was twotwoseven \\uf0b4 twotwoseven that is  what the data set input was all the images in the data set were to twotwoseven \\uf0b4 twotwoseven cross three so  the first thing that they did was they decided to use ninesix filters can you read that  anyways i will say it outright   so they resided to use ninesix filters with a spatial extent of oneone cross oneone a size of four and  padding of zero ok so the moment you see size a stride of four what do you know is going  to happen there is going to be some shrinkage roughly by how much onefourth  right so now can you compute these three things what was wtwo what was htwo and what  was the number of parameters in this layer we will do it for a few of these layers and  then i will just rush through that so whats wtwo going to be you have already done this  computation right the exercise that we did was exactly this computation so there was  fifty-five cross fifty-five and what is the depth going to be i want everyone to say that  student refer time zerofiveonefive  ok and what is the number of parameters  student refer time zerofivetwozero  ninesix into  student oneone  oneone into  student oneone  oneone into three don\\u2019t forget the depth the depth is three here     so that is the number of parameters that they had in this layer ok oneone into oneone into three into  ninesix now what is the next layer going to be a max pooling layer     ok so they had a max pooling layer where they used a three cross three max pooling that  means you are going to pick up max from a three cross three grid and the stride was two that  means we are going to get half the output and now can you tell me what wtwo htwo would  be roughly half of fifty-five fifty-five right so twoseven twoseven     and what is the number of parameter is going to be don\\u2019t be lazy everyone be say it   student zero  zero right so that is the max pooling layer   now what is the size of your input volume at this point  student twoseven  twoseven cross twoseven cross  student ninesix  ninesix as opposed to the original input which was twotwoseven cross twotwoseven cross three so as you keep  progressing your width and height is decreasing but your depth is increasing because  you are using more and more filters to capture more and more patterns in the images     now so you have twoseven \\uf0b4 twoseven \\uf0b4 ninesix then they decided to use twofivesix filters each of size five \\uf0b4 five  with a stride of one and padding of zero ok is it right so how many parameters do you have  now  student refer time zerosixfivethree  twofivesix into   student five into five  five into five into  student ninesix  ninesix    so thats the number of parameters that you will have and the size since would decrease  only by one right because you have a stride of it will decrease by two because a filter size is  five and you have a stride of five ok    so these are the number of parameters we had zerosix million parameters in this layer  what is the next layer going to be pooling     so you do a max pooling again you do a three \\uf0b4 three you do a stride of two so your width in  height is going to decrease the depth does not change remember in max pooling the  depth does not change because the max pooling operation is per feature map it is not  across the depth fine then use a three \\uf0b4 three filter and threeeightfour of those     so how many parameters would you have  student refer time zerosevenfourthree  threeeightfour into three cross three into twofivesix the depth   so now you guys get it so i will not bore you anymore      and then you have a convolution operation again which is a threeeightfour convolutions each of  size three \\uf0b4 three and so many parameters followed by a convolution operation again followed  by a max pooling operation then followed by a fully connected layer    so what would i do to this twofivesix \\uf0b4 two \\uf0b4 two i will fatten it so i will get what dimensional  output  student onezerotwofour  onezerotwofour twofivesix into two into two so this onezerotwofour dimensional vector i am going to fully connect it to  a fourzeroninesix dimensional vector how many parameters four million right four into onezero raise to six  right so roughly four million      then you have another four million another fourzeroninesix vector fully connected how many  parameters   student onesix million  onesix million then you have the one thousand classes that you are interested in right so again  fully connected so you get the full architecture anyone has any questions no one  wants to know why this particular configuration among all the possible configurations  why not onezero layers why not first eight cross eight filters why not nine cross nine filters  unfortunately no one knows laughing  student refer time zeroeightfivenine  so this i mean see this what this is what would happen right now we get into something  known as hyper parameter tuning right so what are the hyper parameters in this  network the kernel size is and the number of filters right so you would have tried a  lot of these things evaluated on the validation set seen which one gives the best  accuracy and then chosen right so that is probably what would have happened but  there is not enough insight into how this particular architecture came up   apart from some things right that three curves three neighborhood sounds reasonable initially  when you have the full image you use larger filter sizes because you want to capture a  lot of things there but once the image has shrunken you use smaller filter sizes so those  are some rational decisions which look reasonable but why these three convolutional filter  layers back to back instead of convolution max pooling convolution max pooling and so  on right  so the some of those things are not clear so just in case you are wondering do not  wonder this is just the architecture this is known as modestly named as alexnet so  that is laughing yeah and so i said that this has eight layers but you clearly see more than  eight layers here so why did i say that has eight layers which are the layers we are not  counting  student refer time onezeroonezero  why   student refer time onezeroonetwo  because they have no parameter right so when you count the number of layers you only  count those layers which have parameters so you have five convolutions and three fully  connected layers     then so the total number of parameters in this network is twosevenfifty-five million parameters and  ok at this point i will and obviously you notice that most of these parameters were there  in the fully connected layer so you had four million here then onesix million here and then  again four million here right   so roughly twofour million of the twoseven million parameters were there in the fully connected  layer you see that skew in the number of parameters ok    and i will just look at the fully connected layer again so the last max pooling layer  actually gave you a twofivesix cross two cross two output you just flatten it to get a onezerotwofour  dimensional vector and then you connected fully to the fourzeroninesix vector right so that is what  i mean by a fully connected layer why do you move max fully   so the reason for that is basically to shrink the size of the image right because after that  if if you keep working with this size right then the number of parameters is going to  really blow up a by using a larger stripe yeah both of them are feasible right so now  see from here remember that we had the original image sizes twotwoseven cross twotwoseven and by the  end we were just left with two cross two  and then adding a fully connected layer on that makes sense right if i had not done this  shrinkage throughout either by increasing the stride of the convolution layer or by doing  max pooling right then you would have left with something of the order of twozerozero cross  twozerozero here and then you have to do a fully connected on top of that is just infeasible right  it just throws away all the hard work that you have done by doing weight sharing and  sparse connectivity right so that is not feasible   there are also papers with say which i think it is titled fully convolutional neural  network which does not have any max pooling layers and they show that that also works  fine in fact when we see vgg net we will see that it has back to back convolution  layers and very few max fully layer right so these are all things which people have  trained   not so many years two years the challenge came out in twozeroonezero and in two thousand and twelve this was used  right so it is like not really a large gap right and if you read the original paper they  had to do a lot of tricks to actually make this work it was not as simple as i am showing  it of course now with all the stability which comes from these platforms tensor flow  pytorch you can probably just go and implement this as it is and you should be able to  reproduce the results but six years back that was not the case there was a lot of hard  work involved in getting this too work and they this was also the paper which  introduced the relu nonlinearity in the context of convolutional neural networks right  so they had to change from sigmoid or tan edge to relu   a lot of these small small things which they had done and at that time it is also not  possible with the existing hardware to train this on the given gpus that you had at that  time so they had to do some splitting across gpus and so on so it was not as simple  as it is today with all the hardware as well as api developments or platform  developments around this right so probably that is why it took two years to yeah sure   so each of these things so after you do the convolution operation you pass it through  the relu nonlinearity ok so what does that mean is that the convolution operation  gave you a feature map every entry here was just a weighted average of the neighbors  right you take this entry or rather you take this feature map and create a new feature map  where every entry here is the sigmoid of every entry here do you get that or not sorry  sigmoid some nonlinearity and they use the relu has the nonlinearity so you do get  everyone gets this so all the convolution layers are followed by a relu nonlinearity  layer  so you get this volume pass it through the relu and get a new volume but i have just  shown that as a single operation it is before pulling so this was the fully connected layer  so now we look at the next architecture which is zfnet    now i am going to compare zfnet with alexnet so on the top you will see alexnet  on the bottom you will see zfnet ok so again the input was the same twotwoseven \\uf0b4 twotwoseven \\uf0b4 three  now instead of oneone cross oneone filters zfnet decided to use seven \\uf0b4 seven filters and their rationale  was that you do not need such large neighborhoods you do not need as small as three \\uf0b4 three  but probably you need at least as much as seven \\uf0b4 seven you do not need oneone \\uf0b4 oneone so that is the  first change that they did and that would also result in some parameter pruning right  because the number of parameters now would be seven cross seven into three so the difference in  the number of parameters at this layer for zfnet which is at the bottom and alexnet  which is at the top would be this how many of you get this ok so thats in the  difference in the number of parameters so now the output volume still remains the  same its fifty-five \\uf0b4 fifty-five \\uf0b4 ninesix     then again they had the same max pooling operation this layer there was no difference  between zfnet and alexnet and then after that you had again layer three which was  exactly the same as alexnet     then layer four again the same as zfnet afterwards layer five instead of threeeightfour filters they  decided to use fiveonetwo filters the rest of the thing remains the same that means the size or  the spatial extent of the filter remains the same that again results in some difference in  the parameters so thats the number of parameters that got added in zfnet as opposed to  alex net   and of course the  oh sorry sorry oh sorry the bottom one is a zfnet yeah that is  correct sorry so in zfnet you had fiveonetwo filters as opposed to threeeightfour filters in alex net ok  is it fine     and then the next layer again instead of threeeightfour filters they had onezerotwofour filters     then again instead of twofivesix they had fiveonetwo filters and then a max pooling layer then the  same dense fully connected layers ok    so everyone gets this this is the difference between the two architectures and this led  to that difference in the error of around three to four percent is that we have seen earlier    so difference the total number of parameters was onefourfive million and of course zfnet had  more parameters because is that it has these more filters in the deeper layers ok so we  go to the last point which is may be more in that vgg net     so again in the case of vgg net the input was ok so i just want to i will not see it  refer time onesixfourone in so the input was again the same it was rgb cross twotwoseven cross  twotwoseven   so this is what the vgg architecture looks like they have so in vgg network  throughout ok wait so how many layers this zfnet have eight so you only count the  pink boxes because the those has ones which have two parameters now vgg net has  slightly more number of layers but in all the convolution layers they use three cross three filters  right from the beginning they use three cross three filters ok so you have the first  convolution layer then another convolution layer another convolution another max  pooling layer followed by two convolution layers then a max pooling layer followed by three  convolution layers max pooling just keep adding box is writing just because you can  and then you have the fully connected layers   so again there is not much intuition for why onesix in fact later on someone came if this is  the vgg onesix architecture because it says onesix layers later on some of someone came up  with the vgg onenine architecture which has onenine layers right so a lot of this is data center  even right so you try your best to get the best possible accuracy on the imagenet data  and that is the architecture you came up with right   but as long as how many of few feel comfortable with what is happening right and i  mean when i say comfortable i mean that you really understand the gory details of  what is happening at each layer in terms of input volumes output volumes number of  parameters how are you going to train this network end to end can you see how are you  going to train this so you will get some loss here that is going to propagate all the way  back to the first layer right and this propagation is going to happen over some sparse  connections that fine now this is one very important point that i have skipped and  which none of you is questioning is everything that is happening here differentiable  student refer time oneeightthreeeight  what happens to max pooling is max pooling or differentiable operation so i am  going to ask you this how are you just note this down how are you going to back  propagate to the max pooling layer because you need to see whether the max pooling  layer is actually a differentiable layer or not  so here i just some statistics about vgg  net everyone is writing that down laughing this perhaps means i will not ask it   the kernel size is three cross three throughout the total number of parameters in non fully  connected layers is onesix million the total number of parameters in fully connected layers  is onetwotwo million so you see that this fully connected layer is really a problem it like really  hogs all the lime that it has the maximum number of parameters there right and so and  the most number of parameters are there in the first fully connected layer because you  have this fiveonetwo \\uf0b4 seven \\uf0b4 seven you remember then alex net and zfnet the last layer was twofivesix \\uf0b4  two \\uf0b4 two which has definitely more manageable than this layer which has grown almost eight  times in size but not even eight actually four into four into two right onesix threetwo times in size right  so that is really blown up the number of parameters in the first fully connected layer  so you just imagine the i mean you have such a deep layer and then you realize that all  the main number of parameters are there in this one particular layer everything else is  much fewer parameters or orders of parameters less number of parameter is less then  this one fully connected layer   \",\n          \"so next we look at on ensemble methods and this is just to build the intuitions for  something known as dropout which is very popular technique in deep neural networks  and convolution neural networks and even recurrent neural networks    so how many you have seen ensembles before seen it in machine learning ensemble  was not done in machinery done with ok ravi did it so as a combine so the ensemble is  essentially just the combining the output of different models to reduce the generalization  error right why does that make sense have these different models all of these would  have different biases and variances right  so now you are combining them so i will end up with a better thing on the test error  right so that is the idea behind ensemble now the models could correspond to different  classifiers right for example here i have a logistic regression and svm and a naive  bayes i have trained them independently using the same data or different subsets of the  data and a test time i am taking a prediction from all of them and then taking an  ensemble of those predictions that is the basic idea  now it could be different instances of the same classifier trained with different hyper  parameters i could have the same neural network a threelayer neural network but trained  with different hyper parameters so the hyper parameters could be learning rate it could  be batch size it could be the number of neurons in each layer and so on right so it  could be same classifier but different hyper parameters different features right so  instead of looking at all the one hundred features that i have given i could train these classifiers  with different subsets of the features ok or different samples of the training data    so bagging is one such ensemble method where you have different instances of the same  classifier which are trained on different samples of the training data ok so i have one  classifiers trained on a subset t one of the training data another classifier trained on a  subset t two of the training data and so on right  and so each of these model is trained with  a different sample of the data    now when would bagging actually work what would you want these classifiers to be  so each classifier is going to make certain errors  what do you want these errors across classifiers to be dependent independent   student independent  independent right so if one classifier makes the errors on certain test instances other  classifier makes errors on a different set of test instances and the third classifier makes  errors on a very different set of instances that is the condition that you are looking for  right there is errors if all of them make error on the same instance then all of them are  collectively going to make an error on the final prediction also right  because it is like i asked three guys all of them gave me the wrong answer so my final  answer is going to be wrong but at least two of these three guys gave me the correct answer  then my final answer is going to be correct right so that means the errors that these  models make i want these errors to be independent if i treat error as a random variable i  want these errors to be independent  so so consider a set of k such logistic regression models suppose that each model  makes an error epsilon i on the test example now let epsilon i be drawn from a zero mean  multivariate normal distribution so the variance is equal to v and how many such  epsilons do i have how many such distributions i am considering  student k  k right because for each classifier there is a distribution so then i can compute the  covariance between these random variables ok i will add that let that covariance be c is  that fineok now the true the error made by the average prediction of all the models is  going to be given by this model one made an error of epsilon one model two made an error of  epsilon two  so the average error is going to be given by this now what is this expected squared  error this is the error this is the expectation this is the square that is the expected  squared error is that fine again this is a square of a sum so it will lead to a lot of terms  of the form epsilon i squares and what will happen now which terms will go to zero    the terms having epsilon i epsilon j again the same thing they are independent so i can  write the expectation of a product as the product of expectations and those expectations  are zero so this is what it is going to look like what is this oh sorry actually we had not  assumed that the covalence  what is this right and what is this covariance i am sorry i have not we had assumed  that there is some covariance said wed not assume they are independent right we would  want it to be independent but in the general case we will assume some covariance and  then i will show you the special case where they are independent  so then how many vs do i have here k right and how many cs do i have here    this summation is k into k minus one right or i equal to one to k and j equal to i plus one to k  fine and so this is what it looks like now can you make some inferences from this  equation this is what the expected mean square error is going to be now think in terms  of variance covariance and tell me when would this be beneficial i have already told  you the answer if the errors are independent what would covariance be zero right  so then what is the mean square error one by k one by k into v right so that means bagging  would work when your classifiers the k classifiers that you are combining    if the errors are independent then the mean square error should actually have been v  right for a single classifier it was v right because mean square error is nothing but the  expectation of the error expectation of epsilon i square which is nothing but v  but if you are if you are combining k classifiers and if these classifiers are independent  in terms of their errors then your mean square error is going to be one by k into v because  this term is going to disappear ok now if your classifiers are perfectly correlated then  what would happen and basically c is equal to v right is that fine so now what would  happen what is the net result if i substitute this as v going to be v right  so if you are all your classifiers are perfectly correlated that is the other case we had  tried taken and all of them are making errors on the same test instances and the same  errors right then you will not get any benefit of doing bagging but if you look at the  other extreme where all your errors are independent or all your classifiers are making  independent errors then you will get a benefit your expected mean square error would go  down from v to one by k into v everyone gets that    so this was just to develop an intuition that taking an ensemble helps right and using  this intuition now we are going to see at how to do this ensemble in the case of deep  neural networks  \",\n          \"so let us start s last lecture we are looking at encoder decoder models and we saw that  a bunch of problems from different domains and different modalities images text videos  and so on and even this cross modal or multi modal applications where you are taking  a video and trying to describe it so video is one modality description texts is another  modality and so on  we were able to propose modals for all of these using this encoder \\u2013 decoder  architecture and then we motivated this attention mechanism where we said that  encoder decoder is trying to do this silly thing where it tries to encode the entire input  once and that is what how humans do it he do this back and forth thing where at every  time step if we are trying to produce a translation or a single word in the translation we  just focus on certain words in the input sentence and kind of ignore the other  so the attention mechanism which is this bunch of equations that you see here that  allowed you a neural way of modelling attention and the key thing to note here is a there  was a supervision for the attention no one actually tells us that this is the portion of the  text which is important at time step t but they still works better because this is the better  modelling choice and i give you that bicycle analogy and also it is a better modelling  choice we are able to no one has given you these supervisions but you are still have  more parameters in the model to learn this kind of a behaviour    and then we also saw that we could actually visualise these attention based and from  some experiments on some papers we saw that actually learn some meaningful  attentions in the particular case on the figure on the on the right hand side so the one  that clearly shows that for a monotonic kind of a translation scenario between english  and french most of the attentions weights are along a diagram and that is exactly what  you would expect right  so that is where we end it  \"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"#words\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 160,\n        \"min\": 89,\n        \"max\": 851,\n        \"num_unique_values\": 102,\n        \"samples\": [\n          436,\n          539,\n          323\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"#characters\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 24,\n        \"max\": 38,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          33,\n          35,\n          30\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Histograms for Duration\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(train_df['duration'], bins=30, color='blue', alpha=0.7)\n",
        "plt.xlabel('Duration(in mins)')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of Duration')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "JWoTkNA6p-mp",
        "outputId": "84710989-117c-442a-d559-0e1180a94afd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Histograms for words\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(train_df['#words'], bins=100, color='green', alpha=0.7)\n",
        "plt.xlabel('#words')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of #words')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "v4FrYtH3qIav",
        "outputId": "7a538e7e-0287-4608-8860-0d75fa964a85"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Histograms for characters\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.hist(train_df['#characters'], bins=10, color='blue', alpha=0.7)\n",
        "plt.xlabel('#characters')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Histogram of #characters')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "2_l8DnMjrqx9",
        "outputId": "3d300148-a17d-41d3-c434-f96298438eb7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wnIBVvNtrzK9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}